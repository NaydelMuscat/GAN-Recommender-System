{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of deep generative models for Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/snipfeed/how-to-implement-deep-generative-models-for-recommender-systems-29110be8971f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "nbr_item = 100  # Define the value of nbr_item according to your specific case\n",
    "\n",
    "generator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(input_shape=(None, nbr_item)),\n",
    "        tf.keras.layers.Dense(nbr_item, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminant = tf.keras.Sequential(\n",
    "          [\n",
    "              tf.keras.layers.InputLayer(input_shape=(None,nbr_item)),\n",
    "              tf.keras.layers.Dense(1,kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "          ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self,user,keep_greater_0 = False):                       \n",
    "    g = self.generator(user)      \n",
    "\n",
    "    if keep_greater_0:\n",
    "        g = tf.multiply(g,tf.cast(user > 0,tf.float32))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminate(self,user,use_sigmoid=True,add_noise=False):\n",
    "    if add_noise:\n",
    "        user = tf.clip_by_value(user + tf.random.truncated_normal(user.shape,mean=0.0,stddev=0.3),0,1)\n",
    "\n",
    "    res = self.discriminant(user)\n",
    "\n",
    "    if use_sigmoid:\n",
    "        res = tf.nn.sigmoid(res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminant_variables(self):\n",
    "    return self.discriminant.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_variables(self):\n",
    "    return self.generator.trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_discriminant(self,user):    \n",
    "    dis_real = self.discriminate(user)\n",
    "    dis_fake = self.discriminate(self.generate(user,True))\n",
    "\n",
    "    return - tf.reduce_mean(tf.log(1. - dis_fake + 10e-5) + tf.log(dis_real + 10e-5)) \n",
    "\n",
    "def compute_loss_generator(self,user): \n",
    "    gen_fake = self.discriminate(self.generate(user,True))\n",
    "    \n",
    "    return - tf.reduce_mean(tf.log(gen_fake+10e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_discriminant(self,batch): \n",
    "        batch_fake = self.generate(batch,True)\n",
    "        dis_real = self.discriminate(batch)\n",
    "        dis_fake = self.discriminate(batch_fake)\n",
    "             \n",
    "        epsilon = tf.random_uniform(shape=(batch.shape[0], 1))\n",
    "        \n",
    "        batch_hat = epsilon * batch + (1. - epsilon) * batch_fake\n",
    "        \n",
    "        with tf.GradientTape() as g:\n",
    "            g.watch(batch_hat)\n",
    "            dis_batch_hat = self.discriminate(batch_hat)\n",
    "        grad_dis_batch_hat = g.gradient(dis_batch_hat, batch_hat) \n",
    "                        \n",
    "        grad_norm = tf.square(tf.norm(grad_dis_batch_hat,axis=-1) - 1)\n",
    "        \n",
    "        return tf.reduce_mean(dis_fake - dis_real + grad_norm * self.lambda_)\n",
    "    \n",
    "def compute_loss_generator(self,user):     \n",
    "        return - tf.reduce_mean(self.discriminate(self.generate(user,True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
